name: Update Shadowrocket Mobile Ads Rules

on:
  schedule:
    - cron: '0 1 * * *'
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/update-mobile-ads-rules.yml'

jobs:
  convert-rules:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download AdGuard filters
        run: |
          curl -o filter_2.txt  https://filters.adtidy.org/ios/filters/2_optimized.txt
          curl -o filter_11.txt https://filters.adtidy.org/ios/filters/11_optimized.txt
          curl -o filter_3.txt  https://filters.adtidy.org/ios/filters/3_optimized.txt
          curl -o filter_4.txt  https://filters.adtidy.org/ios/filters/4_optimized.txt
          curl -o filter_14.txt https://filters.adtidy.org/ios/filters/14_optimized.txt
          curl -o filter_18.txt https://filters.adtidy.org/ios/filters/18_optimized.txt
          curl -o filter_19.txt https://filters.adtidy.org/ios/filters/19_optimized.txt
          curl -o filter_20.txt https://filters.adtidy.org/ios/filters/20_optimized.txt
          curl -o filter_21.txt https://filters.adtidy.org/ios/filters/21_optimized.txt
          curl -o filter_22.txt https://filters.adtidy.org/ios/filters/22_optimized.txt
          curl -o filter_15.txt https://filters.adtidy.org/ios/filters/15_optimized.txt
          curl -o filter_1.txt  https://filters.adtidy.org/ios/filters/1_optimized.txt

      - name: Convert to Shadowrocket format
        run: |
          python3 << 'EOF'
          import re
          import os
          from datetime import datetime

          def convert_adguard_to_shadowrocket(input_files, output_file, existing_rules_file):

              # Список исключений
              whitelist = {
                  'ozon.ru',
              }

              def is_ip_address(s):
                  parts = s.split('.')
                  if len(parts) != 4:
                      return False
                  try:
                      return all(0 <= int(part) <= 255 for part in parts)
                  except ValueError:
                      return False

              def is_whitelisted(domain):
                  if domain in whitelist:
                      return True
                  for white in whitelist:
                      if domain.endswith('.' + white):
                          return True
                  return False

              def is_duplicate(domain, seen_domains):
                  """Проверяет пересечение с первым списком и уже обработанными правилами"""
                  if domain in seen_domains:
                      return True
                  parts = domain.split('.')
                  for i in range(1, len(parts)):
                      parent = '.'.join(parts[i:])
                      if parent in seen_domains:
                          return True
                  return False

              def extract_domain(line):
                  if line.startswith('@@'):
                      return None
                  if '##' in line or '#@#' in line or '#$#' in line:
                      return None
                  if line.startswith('/') and line.endswith('/'):
                      return None
                  if re.match(r'^[^|*]+##', line):
                      return None
                  if '$' in line:
                      if '$document' in line or '$redirect' in line:
                          return None
                      line = line.split('$')[0]

                  if '*' in line:
                      match = re.search(r'\*\.([a-zA-Z0-9][a-zA-Z0-9\-]*\.[a-zA-Z0-9][a-zA-Z0-9\-\.]*[a-zA-Z0-9])\^?', line)
                      if match:
                          domain = match.group(1).strip('.')
                          if domain and '.' in domain and '*' not in domain:
                              parts = domain.split('.')
                              if len(parts[-2]) > 3 and not is_ip_address(domain):
                                  return ('DOMAIN-SUFFIX', domain)
                      return None

                  if line.startswith('||'):
                      match = re.match(r'\|\|([^/\^$\*]+)', line)
                      if match:
                          domain = match.group(1).strip('.')
                          if domain and '/' not in domain and '*' not in domain:
                              if is_ip_address(domain):
                                  return ('IP-CIDR', domain)
                              else:
                                  return ('DOMAIN-SUFFIX', domain)

                  elif line.startswith('|') and not line.startswith('||'):
                      match = re.match(r'\|([^/\^$\*]+)', line)
                      if match:
                          domain = match.group(1).strip('.')
                          if domain and '/' not in domain and '*' not in domain:
                              if is_ip_address(domain):
                                  return ('IP-CIDR', domain)
                              else:
                                  return ('DOMAIN', domain)

                  return None

              # Загружаем существующие правила из первого списка
              seen_domains = set()
              if os.path.exists(existing_rules_file):
                  with open(existing_rules_file, 'r', encoding='utf-8') as f:
                      for line in f:
                          line = line.strip()
                          if line.startswith('DOMAIN-SUFFIX,'):
                              seen_domains.add(line.replace('DOMAIN-SUFFIX,', ''))
                          elif line.startswith('DOMAIN,'):
                              seen_domains.add(line.replace('DOMAIN,', ''))
                          elif line.startswith('IP-CIDR,'):
                              seen_domains.add(line.replace('IP-CIDR,', '').replace('/32', ''))
                  print(f"Loaded {len(seen_domains)} existing rules from {existing_rules_file}")

              shadowrocket_rules = []
              shadowrocket_rules.append(f"# Shadowrocket Mobile Ads Rules")
              shadowrocket_rules.append(f"# Converted from AdGuard filters (iOS)")
              shadowrocket_rules.append(f"# Last updated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")
              shadowrocket_rules.append(f"# Sources:")
              for url in [
                  'https://filters.adtidy.org/ios/filters/2_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/11_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/3_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/4_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/14_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/18_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/19_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/20_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/21_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/22_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/15_optimized.txt',
                  'https://filters.adtidy.org/ios/filters/1_optimized.txt',
              ]:
                  shadowrocket_rules.append(f"#   {url}")
              shadowrocket_rules.append("")

              total_skipped_whitelist = 0
              total_skipped_duplicate = 0
              total_added = 0

              for input_file in input_files:
                  if not os.path.exists(input_file):
                      print(f"File not found, skipping: {input_file}")
                      continue

                  file_added = 0
                  file_skipped_whitelist = 0
                  file_skipped_duplicate = 0

                  with open(input_file, 'r', encoding='utf-8') as f:
                      for line in f:
                          line = line.strip()
                          if not line or line.startswith('!') or line.startswith('#'):
                              continue

                          result = extract_domain(line)
                          if not result:
                              continue

                          rule_type, domain = result

                          if is_whitelisted(domain):
                              file_skipped_whitelist += 1
                              continue

                          if is_duplicate(domain, seen_domains):
                              file_skipped_duplicate += 1
                              continue

                          # Добавляем домен в seen_domains для проверки следующих источников
                          seen_domains.add(domain)

                          if rule_type == 'IP-CIDR':
                              shadowrocket_rules.append(f"IP-CIDR,{domain}/32")
                          elif rule_type == 'DOMAIN-SUFFIX':
                              shadowrocket_rules.append(f"DOMAIN-SUFFIX,{domain}")
                          elif rule_type == 'DOMAIN':
                              shadowrocket_rules.append(f"DOMAIN,{domain}")

                          file_added += 1

                  total_added += file_added
                  total_skipped_whitelist += file_skipped_whitelist
                  total_skipped_duplicate += file_skipped_duplicate
                  print(f"{input_file}: added={file_added}, skipped_duplicate={file_skipped_duplicate}, skipped_whitelist={file_skipped_whitelist}")

              with open(output_file, 'w', encoding='utf-8') as f:
                  f.write('\n'.join(shadowrocket_rules))

              print(f"---")
              print(f"Total added:             {total_added}")
              print(f"Total skipped duplicate: {total_skipped_duplicate}")
              print(f"Total skipped whitelist: {total_skipped_whitelist}")
              print(f"File saved: {output_file}")

          convert_adguard_to_shadowrocket(
              input_files=[
                  'filter_2.txt',
                  'filter_11.txt',
                  'filter_3.txt',
                  'filter_4.txt',
                  'filter_14.txt',
                  'filter_18.txt',
                  'filter_19.txt',
                  'filter_20.txt',
                  'filter_21.txt',
                  'filter_22.txt',
                  'filter_15.txt',
                  'filter_1.txt',
              ],
              output_file='shadowrocket_mobile_ads.conf',
              existing_rules_file='shadowrocket_rules.conf'
          )
          EOF

      - name: Check if there are changes
        id: changes
        run: |
          git add shadowrocket_mobile_ads.conf
          git diff --cached --quiet || echo "changed=true" >> $GITHUB_OUTPUT

      - name: Commit and push if changed
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git commit -m "Update Mobile Ads rules - $(date +'%Y-%m-%d %H:%M:%S UTC')"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: shadowrocket-mobile-ads-rules
          path: shadowrocket_mobile_ads.conf
          retention-days: 30
